{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install boto3\n",
    "# !ls ./dataset/bed_pillow_reviews/1-Beckham/\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('punkt') # for sent_tokenize\n",
    "# nltk.download('stopwords') \n",
    "# nltk.download('wordnet') # for WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "from credentials import ACCESS_KEY, SECRET_KEY\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Text preprocessing/analysis\n",
    "import re\n",
    "from nltk import word_tokenize, sent_tokenize, FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "from itertools import groupby \n",
    "\n",
    "\n",
    "# import seaborn as sns\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# import io\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "# import base64\n",
    "\n",
    "# sns.set()\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_DIR = './dataset/bed_pillow_reviews/1-Beckham/'\n",
    "all_files = sorted([os.path.join(CURRENT_DIR, f) for f in os.listdir(CURRENT_DIR)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pillow_reviews = pd.concat((pd.read_csv(f, index_col=None, header=0) for f in all_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pillow_reviews['ReviewCountry'], pillow_reviews['ReviewDate'] = pillow_reviews['Date'].str.split(' on ', 1).str\n",
    "\n",
    "pillow_reviews['ReviewDate'] = pd.to_datetime(pillow_reviews['ReviewDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pillow_reviews['Period'] = pillow_reviews['ReviewDate'].apply(lambda x: \"%d-%d\" % (x.year, x.week))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date             10686\n",
       "Author           10686\n",
       "Verified         10686\n",
       "Helpful          10686\n",
       "Title            10685\n",
       "Body             10686\n",
       "Rating           10686\n",
       "Images           10686\n",
       "Videos           10686\n",
       "URL              10686\n",
       "Variation        10686\n",
       "Style            10686\n",
       "ReviewCountry    10686\n",
       "ReviewDate       10686\n",
       "Period           10686\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pillow_reviews['ReviewCountry'].unique()\n",
    "\n",
    "# Contains Image OR Video\n",
    "pillow_reviews[(pillow_reviews.Images!='-') | (pillow_reviews.Videos!='-')].count()\n",
    "\n",
    "# Contains No Image Nor Video\n",
    "pillow_reviews[(pillow_reviews.Images=='-') & (pillow_reviews.Videos=='-')].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For TABLEAU USE\n",
    "# pillow_reviews.to_csv('dataset/pillow_reviews_{}.csv'.format(re.sub(r'(-|:| )', '', str(datetime.now())[:-7])), encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variation</th>\n",
       "      <th>Rating</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">B01LYC1XSM</th>\n",
       "      <th>1</th>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">B01LYNW421</th>\n",
       "      <th>1</th>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Rating\n",
       "                   count\n",
       "Variation  Rating       \n",
       "-          1          13\n",
       "           2          10\n",
       "           3          12\n",
       "           4          25\n",
       "           5          24\n",
       "B01LYC1XSM 1         582\n",
       "           2         262\n",
       "           3         331\n",
       "           4         392\n",
       "           5        1118\n",
       "B01LYNW421 1        1220\n",
       "           2         735\n",
       "           3         930\n",
       "           4        1484\n",
       "           5        3858"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pillow_reviews.groupby(['Variation', 'Rating']).agg({'Rating': [\"count\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prod_1 = pillow_reviews[pillow_reviews['Variation'] == 'B01LYNW421']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_1_good = prod_1[prod_1['Rating'] >= 4]\n",
    "prod_1_ok = prod_1[prod_1['Rating'] == 3]\n",
    "prod_1_bad = prod_1[prod_1['Rating'] <= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_1_good_reviews = prod_1_good.reset_index().Body\n",
    "prod_1_ok_reviews = prod_1_ok.reset_index().Body\n",
    "prod_1_bad_reviews = prod_1_bad.reset_index().Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strings_split = combined_strings.split()\n",
    "# freq_splits = FreqDist(strings_split)\n",
    "# print(freq_splits.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# short = set(s for s in strings_split if len(s)<4)\n",
    "# short = [(s, freq_splits[s]) for s in short]\n",
    "# short.sort(key=lambda x:x[1], reverse=True)\n",
    "# short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# long = set(s for s in strings_split if len(s)>10)\n",
    "# long = [(s, freq_splits[s]) for s in long]\n",
    "# long.sort(key=lambda x:x[1], reverse=True)\n",
    "# long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise(pattern, strings, freq):\n",
    "    \"\"\"Summarise strings matching a pattern.\"\"\"\n",
    "    # Find matches\n",
    "    compiled_pattern = re.compile(pattern)\n",
    "    matches = [s for s in strings if compiled_pattern.search(s)]\n",
    "    \n",
    "    # Print volume and proportion of matches\n",
    "    print(\"{} strings, that is {:.2%} of total\".format(len(matches), len(matches)/ len(strings)))\n",
    "    \n",
    "    # Create list of tuples containing matches and their frequency\n",
    "    output = [(s, freq[s]) for s in set(matches)]\n",
    "    output.sort(key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise(r\"\\d\", strings_split, freq_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyphenated words\n",
    "# summarise(r\"\\w+-+\\w+\", strings_split, freq_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 strings, that is 0.04% of total\n"
     ]
    }
   ],
   "source": [
    "def find_outlaw(word):\n",
    "    \"\"\"Find words that contain a same character 3+ times in a row.\"\"\"\n",
    "    is_outlaw = False\n",
    "    for i, letter in enumerate(word):\n",
    "        if i > 1:\n",
    "            if word[i] == word[i-1] == word[i-2] and word[i].isalpha():\n",
    "                is_outlaw = True\n",
    "                break\n",
    "    return is_outlaw\n",
    "outlaws = [s for s in strings_split if find_outlaw(s)]\n",
    "print(\"{} strings, that is {:.2%} of total\".format(len(outlaws), len(outlaws)/ len(strings_split)))\n",
    "outlaw_freq = [(s, freq_splits[s]) for s in set(outlaws)]\n",
    "outlaw_freq.sort(key=lambda x:x[1], reverse=True)\n",
    "# outlaw_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_token(reviews):\n",
    "    \n",
    "    #remove all grams starting with period\n",
    "    def clean_grams(ngram_counter):\n",
    "        begins_with_period = []\n",
    "        for gram in ngram_counter:\n",
    "            if gram[0] == '.':\n",
    "                begins_with_period.append(gram)\n",
    "        for gram in begins_with_period:\n",
    "            del ngram_counter[gram]\n",
    "    \n",
    "    combined_strings = \" \".join(reviews)\n",
    "\n",
    "    tokeniser = RegexpTokenizer(\"[A-Za-z\\']+|\\.\")\n",
    "    tokens = tokeniser.tokenize(combined_strings)\n",
    "    \n",
    "    # Remove repeat\n",
    "    deduped_tokens = [i[0] for i in groupby(tokens)]\n",
    "    \n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    tokens_norm = [lemmatiser.lemmatize(t.lower(), \"v\") for t in deduped_tokens]\n",
    "    \n",
    "    return tokens_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_tree(tokens):\n",
    "    def _word_tree(head=None, show_count=20, trailing=2):\n",
    "        if type(head)==str:\n",
    "            head = head.lower().split()\n",
    "        trailing_grams = trailing \n",
    "        if head != None:\n",
    "            trailing_grams += len(head)\n",
    "        if head==None:\n",
    "            ngram_counter = Counter(ngrams(tokens, trailing_grams))\n",
    "        else:\n",
    "            ngram_counter = Counter([gram for gram in ngrams(tokens, trailing_grams) if gram[:len(head)] == tuple(head)])\n",
    "        clean_grams(ngram_counter)\n",
    "        \n",
    "        for (text, idx) in ngram_counter.most_common(show_count):\n",
    "            print(f\"{idx} - {' '.join(text)}\")\n",
    "#         return ngram_counter\n",
    "    return _word_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod_1_bad_reviews\n",
    "# prod_1_good_reviews\n",
    "\n",
    "TEXT_TO_ANALYZE = prod_1_bad_reviews\n",
    "\n",
    "word_tree = get_word_tree(generate_token(TEXT_TO_ANALYZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 - no support at all\n",
      "35 - i wake up with\n",
      "31 - at all . i\n",
      "29 - support at all .\n",
      "27 - you lay your head\n",
      "25 - wake up with neck\n",
      "24 - be not the same\n",
      "24 - pillow . they be\n",
      "23 - not comfortable at all\n",
      "23 - i be look for\n",
      "22 - as soon as you\n",
      "22 - your head on it\n",
      "22 - you put your head\n",
      "22 - put your head on\n",
      "22 - wake up with a\n",
      "22 - lay your head on\n",
      "22 - waste of money .\n",
      "22 - pillow i have ever\n",
      "21 - a side sleeper and\n",
      "21 - these pillow . i\n",
      "21 - i buy these pillow\n",
      "20 - i be very disappoint\n",
      "20 - these pillow be not\n",
      "19 - up with neck pain\n",
      "19 - these pillow . they\n"
     ]
    }
   ],
   "source": [
    "word_tree(None, 25, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - as soon as you rest your head on it sink down . there be not much support and i\n",
      "1 - as soon as you put your head on it the pillow flatten out . it be quick to come\n",
      "1 - as soon as you rest your head on it . it do not matter with any sleep position i\n",
      "1 - as soon as you rest your head on them it sink to nearly flat . way too soft .\n",
      "1 - as soon as you lay your head down you sink all the way through . zero support . they\n",
      "1 - as soon as you lay your head on these you can feel it sink to the bottom of the\n",
      "1 - as soon as you lay your head on them . i suppose if you like the feel of sleep\n",
      "1 - as soon as you lay on them . as i state the st set be amaze . soft but\n",
      "1 - as soon as you put your head on it . i go back to use my old pillow immediately\n",
      "1 - as soon as you lay down there s no support . you lay down and your head hit the\n",
      "1 - as soon as you put your head on it you sink down to the mattress . return these and\n",
      "1 - as soon as you receive the product after sleep on it for one week it s just terrible .\n",
      "1 - as soon as you put your head on them . terrible pillow flat and not comfortable maybe i just\n",
      "1 - as soon as you put your head down . not worth it feel and sleep like flat dollar store\n",
      "1 - as soon as you lay on it the pillow go flat select star bc force to in order to\n",
      "1 - as soon as you lay on them . they be very uncomfortable . waste of money hard to sleep\n",
      "1 - as soon as you lay on it there no neck support at all . you wake up with a\n",
      "1 - as soon as you put any pressure on them they go flat again . they aren't firm they aren't\n",
      "1 - as soon as you lay on them they deflate . return these be super thin and low quality .\n",
      "1 - as soon as you put your head on the pillow you sink right in all the way to your\n",
      "1 - as soon as you lay your head on them . they be not firm in any way whatsoever not\n",
      "1 - as soon as you lay your head on these it go flat even if you work at fluff it\n"
     ]
    }
   ],
   "source": [
    "word_tree('as soon as you', 25, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = stopwords.words(\"english\")\n",
    "# print(f\"There are {len(stop_words)} stopwords.\\n\")\n",
    "# print(stop_words)\n",
    "# my_stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', \n",
    "#                 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \n",
    "#                 \"you'd\", 'your', 'yours', 'yourself', 'yourselves', \n",
    "#                 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', \n",
    "#                 'hers', 'herself', 'it', \"it's\", 'its', 'itself', \n",
    "#                 'they', 'them', 'their', 'theirs', 'themselves', \n",
    "#                 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 's', 't', 'can', 'will', 'just', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_review = pillow_reviews.Body[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# comprehend = boto3.client(\n",
    "#     service_name='comprehend', \n",
    "#     region_name='us-west-2',\n",
    "#     aws_access_key_id=ACCESS_KEY,\n",
    "#     aws_secret_access_key=SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling DetectKeyPhrases\n",
      "{\n",
      "    \"KeyPhrases\": [\n",
      "        {\n",
      "            \"BeginOffset\": 19,\n",
      "            \"EndOffset\": 32,\n",
      "            \"Score\": 0.9999992251396179,\n",
      "            \"Text\": \"these pillows\"\n",
      "        },\n",
      "        {\n",
      "            \"BeginOffset\": 43,\n",
      "            \"EndOffset\": 60,\n",
      "            \"Score\": 1.0,\n",
      "            \"Text\": \"the perfect combo\"\n",
      "        },\n",
      "        {\n",
      "            \"BeginOffset\": 124,\n",
      "            \"EndOffset\": 137,\n",
      "            \"Score\": 1.0,\n",
      "            \"Text\": \"less soreness\"\n",
      "        },\n",
      "        {\n",
      "            \"BeginOffset\": 141,\n",
      "            \"EndOffset\": 148,\n",
      "            \"Score\": 0.9999998211860657,\n",
      "            \"Text\": \"my neck\"\n",
      "        },\n",
      "        {\n",
      "            \"BeginOffset\": 182,\n",
      "            \"EndOffset\": 202,\n",
      "            \"Score\": 0.9999993443489075,\n",
      "            \"Text\": \"a memory foam pillow\"\n",
      "        },\n",
      "        {\n",
      "            \"BeginOffset\": 274,\n",
      "            \"EndOffset\": 287,\n",
      "            \"Score\": 0.9999448657035828,\n",
      "            \"Text\": \"these pillows\"\n",
      "        },\n",
      "        {\n",
      "            \"BeginOffset\": 301,\n",
      "            \"EndOffset\": 320,\n",
      "            \"Score\": 0.999999463558197,\n",
      "            \"Text\": \"a vacuum-sealed bag\"\n",
      "        },\n",
      "        {\n",
      "            \"BeginOffset\": 375,\n",
      "            \"EndOffset\": 390,\n",
      "            \"Score\": 0.9998744130134583,\n",
      "            \"Text\": \"no mold problem\"\n",
      "        }\n",
      "    ],\n",
      "    \"ResponseMetadata\": {\n",
      "        \"HTTPHeaders\": {\n",
      "            \"content-length\": \"682\",\n",
      "            \"content-type\": \"application/x-amz-json-1.1\",\n",
      "            \"date\": \"Sat, 08 May 2021 07:34:00 GMT\",\n",
      "            \"x-amzn-requestid\": \"b2063ecc-0dae-4135-b673-f984b6d181f5\"\n",
      "        },\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"RequestId\": \"b2063ecc-0dae-4135-b673-f984b6d181f5\",\n",
      "        \"RetryAttempts\": 0\n",
      "    }\n",
      "}\n",
      "End of DetectKeyPhrases\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# text = single_review\n",
    "\n",
    "# print('Calling DetectKeyPhrases')\n",
    "# print(json.dumps(comprehend.detect_key_phrases(Text=text, LanguageCode='en'), sort_keys=True, indent=4))\n",
    "# print('End of DetectKeyPhrases\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
