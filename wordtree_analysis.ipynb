{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Text preprocessing/analysis\n",
    "import re\n",
    "from nltk import word_tokenize, sent_tokenize, FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "from itertools import groupby \n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# import io\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "# import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(pathname):\n",
    "    return sorted([os.path.join(pathname, f) for f in os.listdir(pathname)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data/bed_pillow_reviews/1-Beckham/'\n",
    "# DATA_DIR = './data/bed_pillow_reviews/2-down alt/'\n",
    "all_files = get_paths(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(files, separator=','):\n",
    "    \"\"\"\n",
    "    Takes a list of pathnames and individually reads then concats them into a single DataFrame which is returned.\n",
    "    Can handle Excel files, csv, or delimiter separated text.\n",
    "    \"\"\"\n",
    "    processed_files = []\n",
    "    for file in files:\n",
    "        if file.lower().endswith('.xlsx') or file.lower().endswith('.xls'):\n",
    "            processed_files.append(pd.read_excel(file, index_col=None, header=0))\n",
    "        elif file.lower().endswith('.csv'):\n",
    "            processed_files.append(pd.read_csv(file, index_col=None, header=0))\n",
    "        else:\n",
    "            processed_files.append(pd.read_csv(file, sep=separator, index_col=None, header=0))\n",
    "    completed_df = pd.concat(processed_files, ignore_index=True)\n",
    "    return completed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "pillow_reviews = read_files(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Author</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Helpful</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Images</th>\n",
       "      <th>Videos</th>\n",
       "      <th>URL</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Style</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reviewed in the United States on February 16, ...</td>\n",
       "      <td>Mark 2727</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Long review, but I'd recommend these Sleep Res...</td>\n",
       "      <td>OK, let's clear up a few things:1)  I am a rea...</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.com/gp/customer-reviews/RXV...</td>\n",
       "      <td>B01LYNW421</td>\n",
       "      <td>Size: Queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reviewed in the United States on July 7, 2018</td>\n",
       "      <td>Jessica Harvey</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>Pickiest Boyfriend EVER rates these 10 out of 10</td>\n",
       "      <td>I was originally going to go with 4 stars on t...</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.com/gp/customer-reviews/R2Q...</td>\n",
       "      <td>B01LYC1XSM</td>\n",
       "      <td>Size: King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reviewed in the United States on January 30, 2019</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>The crack of pillows!!</td>\n",
       "      <td>I was awake in the middle of the night tossing...</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.com/gp/customer-reviews/R1O...</td>\n",
       "      <td>B01LYNW421</td>\n",
       "      <td>Size: Queen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reviewed in the United States on March 17, 2018</td>\n",
       "      <td>Lynn E. G. Salgado</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>From a \"Pillow Snob\"</td>\n",
       "      <td>WELL!  I have herniated discs in my neck and h...</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.com/gp/customer-reviews/R21...</td>\n",
       "      <td>B01LYC1XSM</td>\n",
       "      <td>Size: King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reviewed in the United States on February 12, ...</td>\n",
       "      <td>Sarah Hagelin</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>So comfortable!</td>\n",
       "      <td>So happy I ordered these pillows! They are the...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://images-na.ssl-images-amazon.com/images...</td>\n",
       "      <td>-</td>\n",
       "      <td>https://www.amazon.com/gp/customer-reviews/R30...</td>\n",
       "      <td>B01LYNW421</td>\n",
       "      <td>Size: Queen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Date              Author  \\\n",
       "0  Reviewed in the United States on February 16, ...           Mark 2727   \n",
       "1      Reviewed in the United States on July 7, 2018      Jessica Harvey   \n",
       "2  Reviewed in the United States on January 30, 2019              Amanda   \n",
       "3    Reviewed in the United States on March 17, 2018  Lynn E. G. Salgado   \n",
       "4  Reviewed in the United States on February 12, ...       Sarah Hagelin   \n",
       "\n",
       "  Verified Helpful                                              Title  \\\n",
       "0      yes     yes  Long review, but I'd recommend these Sleep Res...   \n",
       "1      yes     yes   Pickiest Boyfriend EVER rates these 10 out of 10   \n",
       "2      yes     yes                             The crack of pillows!!   \n",
       "3      yes     yes                               From a \"Pillow Snob\"   \n",
       "4      yes     yes                                    So comfortable!   \n",
       "\n",
       "                                                Body  Rating  \\\n",
       "0  OK, let's clear up a few things:1)  I am a rea...       5   \n",
       "1  I was originally going to go with 4 stars on t...       5   \n",
       "2  I was awake in the middle of the night tossing...       5   \n",
       "3  WELL!  I have herniated discs in my neck and h...       5   \n",
       "4  So happy I ordered these pillows! They are the...       5   \n",
       "\n",
       "                                              Images Videos  \\\n",
       "0                                                  -      -   \n",
       "1                                                  -      -   \n",
       "2                                                  -      -   \n",
       "3                                                  -      -   \n",
       "4  https://images-na.ssl-images-amazon.com/images...      -   \n",
       "\n",
       "                                                 URL   Variation        Style  \n",
       "0  https://www.amazon.com/gp/customer-reviews/RXV...  B01LYNW421  Size: Queen  \n",
       "1  https://www.amazon.com/gp/customer-reviews/R2Q...  B01LYC1XSM   Size: King  \n",
       "2  https://www.amazon.com/gp/customer-reviews/R1O...  B01LYNW421  Size: Queen  \n",
       "3  https://www.amazon.com/gp/customer-reviews/R21...  B01LYC1XSM   Size: King  \n",
       "4  https://www.amazon.com/gp/customer-reviews/R30...  B01LYNW421  Size: Queen  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pillow_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaeldu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pillow_reviews['ReviewCountry'], pillow_reviews['ReviewDate'] = pillow_reviews['Date'].str.split(' on ', 1).str\n",
    "\n",
    "pillow_reviews['ReviewDate'] = pd.to_datetime(pillow_reviews['ReviewDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews with EITHER Image or Video: 310\n",
      "Reviews with NO Image or Video: 10686\n"
     ]
    }
   ],
   "source": [
    "# Contains Image OR Video\n",
    "print(f\"Reviews with EITHER Image or Video: {len(pillow_reviews[(pillow_reviews.Images!='-') | (pillow_reviews.Videos!='-')])}\")\n",
    "\n",
    "# Contains No Image Nor Video\n",
    "print(f\"Reviews with NO Image or Video: {len(pillow_reviews[(pillow_reviews.Images=='-') & (pillow_reviews.Videos=='-')])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT FOR TABLEAU USE\n",
    "# pillow_reviews.to_csv('dataset/pillow_reviews_{}.csv'.format(re.sub(r'(-|:| )', '', str(datetime.now())[:-7])), encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prod_1 = pillow_reviews[pillow_reviews['Variation'] == 'B01LYNW421']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_1_good = prod_1[prod_1['Rating'] >= 4]\n",
    "# prod_1_ok = prod_1[prod_1['Rating'] == 3]\n",
    "prod_1_bad = prod_1[prod_1['Rating'] <= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_1_good_reviews = prod_1_good.reset_index()['Body']\n",
    "# prod_1_ok_reviews = prod_1_ok.reset_index()['Body']\n",
    "prod_1_bad_reviews = prod_1_bad.reset_index()['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise(pattern, strings, freq):\n",
    "    \"\"\"Summarise strings matching a pattern.\"\"\"\n",
    "    # Find matches\n",
    "    compiled_pattern = re.compile(pattern)\n",
    "    matches = [s for s in strings if compiled_pattern.search(s)]\n",
    "    \n",
    "    # Print volume and proportion of matches\n",
    "    print(\"{} strings, that is {:.2%} of total\".format(len(matches), len(matches)/ len(strings)))\n",
    "    \n",
    "    # Create list of tuples containing matches and their frequency\n",
    "    output = [(s, freq[s]) for s in set(matches)]\n",
    "    output.sort(key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outlaw(word):\n",
    "    \"\"\"Find words that contain a same character 3+ times in a row.\"\"\"\n",
    "    is_outlaw = False\n",
    "    for i, letter in enumerate(word):\n",
    "        if i > 1:\n",
    "            if word[i] == word[i-1] == word[i-2] and word[i].isalpha():\n",
    "                is_outlaw = True\n",
    "                break\n",
    "    return is_outlaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from credentials import ACCESS_KEY, SECRET_KEY, \n",
    "\n",
    "# comprehend = boto3.client(\n",
    "#     service_name='comprehend', \n",
    "#     region_name='us-west-2',\n",
    "#     aws_access_key_id=ACCESS_KEY,\n",
    "#     aws_secret_access_key=SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = single_review\n",
    "\n",
    "# print('Calling DetectKeyPhrases')\n",
    "# print(json.dumps(comprehend.detect_key_phrases(Text=text, LanguageCode='en'), sort_keys=True, indent=4))\n",
    "# print('End of DetectKeyPhrases\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to Postgres from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import Column, Integer, JSON, String, Text, text, Date\n",
    "\n",
    "from credentials import POSTGRESQL_USER, POSTGRESQL_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class Review(Base):\n",
    "    __tablename__ = 'reviews'\n",
    "\n",
    "    review_id = Column(Integer, primary_key=True, server_default=text(\"nextval('reviews_review_id_seq'::regclass)\"))\n",
    "    content = Column(Text, nullable=False)\n",
    "    meta_data = Column(JSON)\n",
    "    product_id = Column(String(80), nullable=False)\n",
    "    variation = Column(String(80))\n",
    "    review_date = Column(Date)\n",
    "    rater_id = Column(String(80))\n",
    "    product_rating = Column(Integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql+psycopg2://{POSTGRESQL_USER}:{POSTGRESQL_PASSWORD}@localhost:5432/hooray_analysis_db\")\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "session = sessionmaker(bind=engine)\n",
    "s = session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for file in all_files:\n",
    "        with open(file, encoding='utf-8-sig') as fh:\n",
    "            csvreader = csv.reader(fh, delimiter=',')\n",
    "            headers = []\n",
    "            for idx, row in enumerate(csvreader):\n",
    "                if idx == 0:\n",
    "                    headers = row\n",
    "                else:\n",
    "                    item = dict(zip(headers, row))\n",
    "                    entry_item = {\n",
    "                        'product_id': 'B01LYNW421',\n",
    "                        'variation': item['Variation'],\n",
    "                        'content': item['Body'],\n",
    "                        'product_rating': item['Rating'],\n",
    "                        'rater_id': item['Author'],\n",
    "                        'review_date': item['Date'].split(' on ')[1],\n",
    "                        'meta_data': {k:d for (k, d) in item.items() if k not in ['Variation', 'Body', 'Rating', 'Author', 'Date']}\n",
    "                        }\n",
    "                    new_review = Review(**entry_item)\n",
    "                    s.add(new_review)\n",
    "    s.commit()\n",
    "except():\n",
    "    s.rollback()\n",
    "    s.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
